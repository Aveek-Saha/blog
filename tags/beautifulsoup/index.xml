<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>BeautifulSoup on Aveek's Blog</title><link>https://home.aveek.io/blog/tags/beautifulsoup/</link><description>Recent content in BeautifulSoup on Aveek's Blog</description><generator>Hugo -- gohugo.io</generator><managingEditor>aveek.s98@gmail.com (Aveek Saha)</managingEditor><webMaster>aveek.s98@gmail.com (Aveek Saha)</webMaster><lastBuildDate>Mon, 13 May 2019 00:00:00 +0000</lastBuildDate><atom:link href="https://home.aveek.io/blog/tags/beautifulsoup/index.xml" rel="self" type="application/rss+xml"/><item><title>Web Scraping with Python</title><link>https://home.aveek.io/blog/post/web-scraping-with-python/</link><pubDate>Mon, 13 May 2019 00:00:00 +0000</pubDate><author>aveek.s98@gmail.com (Aveek Saha)</author><guid>https://home.aveek.io/blog/post/web-scraping-with-python/</guid><description>&lt;p>Code for this tutorial can be found on &lt;a href="https://gist.github.com/Aveek-Saha/860464a7b52c5bab781f870dcb73ed57">&lt;code>Github&lt;/code>&lt;/a>&lt;/p>
&lt;h1 id="introduction">Introduction&lt;/h1>
&lt;p>Web scraping is a useful tool for extracting data from websites, especially those that don&amp;rsquo;t provide an API. In this post, I&amp;rsquo;ll show you how you can use web scraping to generate a dataset from a webpage.&lt;/p>
&lt;p>For this example we will be using a website called &lt;a href="https://trendogate.com/place/23424977">trendogate&lt;/a> which is a website that displays trending twitter hashtags on a given day based on region. Our goal will be to retrieve hashtags that are currently trending in the US.&lt;/p>
&lt;p>To do this we will primarily be using two libraries:&lt;/p>
&lt;h2 id="1-urllib">1. Urllib&lt;/h2>
&lt;blockquote>
&lt;p>Urllib is a Python module that can be used for opening URLs. It defines functions and classes to help in URL actions. With Python you can also access and retrieve data from the internet like XML, HTML, JSON, etc.&lt;/p>
&lt;/blockquote>
&lt;p>Urllib is going to help us retrieve the web page we want to scrape.&lt;/p>
&lt;p>To install Urllib-&lt;/p>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-bash" data-lang="bash">pip install urllib
&lt;/code>&lt;/pre>&lt;/div>&lt;h2 id="2-beautiful-soup">2. Beautiful Soup&lt;/h2>
&lt;blockquote>
&lt;p>Beautiful Soup is a Python package for parsing HTML and XML documents. It creates a parse tree for parsed pages that can be used to extract data from HTML, which is useful for web scraping&lt;/p>
&lt;/blockquote>
&lt;p>Once we have the page we need from Urllib, we&amp;rsquo;re going to use Beautiful Soup to create a parse tree and extract the information we need from the page.&lt;/p>
&lt;p>To install Beautiful Soup&lt;/p>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-bash" data-lang="bash">pip install BeautifulSoup4
&lt;/code>&lt;/pre>&lt;/div>&lt;!-- raw HTML omitted -->
&lt;h1 id="analysing-the-web-page">Analysing the web page&lt;/h1>
&lt;p>To scrape a webpage you need to be familiar with the structure of the HTML tags in that page. So right click on the page you want to scrape and select Inspect.&lt;/p>
&lt;p>The &lt;a href="https://trendogate.com/place/23424977">trendogate&lt;/a> webpage looks like this:&lt;/p>
&lt;p>&lt;img src="https://home.aveek.io/blog/scraping/scraping_site.png" alt="Trendogate">&lt;/p>
&lt;p>We are interested in the trending today section. If we inspect it we can see the HTML structure.&lt;/p>
&lt;p>&lt;img src="https://home.aveek.io/blog/scraping/scrape_html_tag.png" alt="HTML tags">&lt;/p>
&lt;p>Today&amp;rsquo;s trending hashtags are in an unordered list of class &lt;code>list-group&lt;/code> that looks something like this:
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-html" data-lang="html">&lt;span class="p">&amp;lt;&lt;/span>&lt;span class="nt">ul&lt;/span> &lt;span class="na">class&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="s">&amp;#34;list-group&amp;#34;&lt;/span>&lt;span class="p">&amp;gt;&lt;/span>
&lt;span class="p">&amp;lt;&lt;/span>&lt;span class="nt">li&lt;/span> &lt;span class="na">class&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="s">&amp;#34;list-group-item&amp;#34;&lt;/span>&lt;span class="p">&amp;gt;&amp;lt;&lt;/span>&lt;span class="nt">a&lt;/span> &lt;span class="na">href&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="s">&amp;#34;/trend/79334795&amp;#34;&lt;/span>&lt;span class="p">&amp;gt;&lt;/span> #TriviaTuesday&lt;span class="p">&amp;lt;/&lt;/span>&lt;span class="nt">a&lt;/span>&lt;span class="p">&amp;gt;&amp;lt;/&lt;/span>&lt;span class="nt">li&lt;/span>&lt;span class="p">&amp;gt;&lt;/span>
&lt;span class="p">&amp;lt;&lt;/span>&lt;span class="nt">li&lt;/span> &lt;span class="na">class&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="s">&amp;#34;list-group-item&amp;#34;&lt;/span>&lt;span class="p">&amp;gt;&amp;lt;&lt;/span>&lt;span class="nt">a&lt;/span> &lt;span class="na">href&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="s">&amp;#34;/trend/79334794&amp;#34;&lt;/span>&lt;span class="p">&amp;gt;&lt;/span> #IA02&lt;span class="p">&amp;lt;/&lt;/span>&lt;span class="nt">a&lt;/span>&lt;span class="p">&amp;gt;&amp;lt;/&lt;/span>&lt;span class="nt">li&lt;/span>&lt;span class="p">&amp;gt;&lt;/span>
&lt;span class="p">&amp;lt;&lt;/span>&lt;span class="nt">li&lt;/span> &lt;span class="na">class&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="s">&amp;#34;list-group-item&amp;#34;&lt;/span>&lt;span class="p">&amp;gt;&amp;lt;&lt;/span>&lt;span class="nt">a&lt;/span> &lt;span class="na">href&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="s">&amp;#34;/trend/79334793&amp;#34;&lt;/span>&lt;span class="p">&amp;gt;&lt;/span> #livelocaldigital&lt;span class="p">&amp;lt;/&lt;/span>&lt;span class="nt">a&lt;/span>&lt;span class="p">&amp;gt;&amp;lt;/&lt;/span>&lt;span class="nt">li&lt;/span>&lt;span class="p">&amp;gt;&lt;/span>
&lt;span class="p">&amp;lt;&lt;/span>&lt;span class="nt">li&lt;/span> &lt;span class="na">class&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="s">&amp;#34;list-group-item&amp;#34;&lt;/span>&lt;span class="p">&amp;gt;&amp;lt;&lt;/span>&lt;span class="nt">a&lt;/span> &lt;span class="na">href&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="s">&amp;#34;/trend/79334792&amp;#34;&lt;/span>&lt;span class="p">&amp;gt;&lt;/span> #MLW19&lt;span class="p">&amp;lt;/&lt;/span>&lt;span class="nt">a&lt;/span>&lt;span class="p">&amp;gt;&amp;lt;/&lt;/span>&lt;span class="nt">li&lt;/span>&lt;span class="p">&amp;gt;&lt;/span>
&lt;span class="p">&amp;lt;&lt;/span>&lt;span class="nt">li&lt;/span> &lt;span class="na">class&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="s">&amp;#34;list-group-item&amp;#34;&lt;/span>&lt;span class="p">&amp;gt;&amp;lt;&lt;/span>&lt;span class="nt">a&lt;/span> &lt;span class="na">href&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="s">&amp;#34;/trend/79334791&amp;#34;&lt;/span>&lt;span class="p">&amp;gt;&lt;/span> #TuesdayTip&lt;span class="p">&amp;lt;/&lt;/span>&lt;span class="nt">a&lt;/span>&lt;span class="p">&amp;gt;&amp;lt;/&lt;/span>&lt;span class="nt">li&lt;/span>&lt;span class="p">&amp;gt;&lt;/span>
&lt;span class="p">&amp;lt;&lt;/span>&lt;span class="nt">li&lt;/span> &lt;span class="na">class&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="s">&amp;#34;list-group-item&amp;#34;&lt;/span>&lt;span class="p">&amp;gt;&amp;lt;&lt;/span>&lt;span class="nt">a&lt;/span> &lt;span class="na">href&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="s">&amp;#34;/trend/79334790&amp;#34;&lt;/span>&lt;span class="p">&amp;gt;&lt;/span> #VoteCox&lt;span class="p">&amp;lt;/&lt;/span>&lt;span class="nt">a&lt;/span>&lt;span class="p">&amp;gt;&amp;lt;/&lt;/span>&lt;span class="nt">li&lt;/span>&lt;span class="p">&amp;gt;&lt;/span>
&lt;span class="p">&amp;lt;&lt;/span>&lt;span class="nt">li&lt;/span> &lt;span class="na">class&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="s">&amp;#34;list-group-item&amp;#34;&lt;/span>&lt;span class="p">&amp;gt;&amp;lt;&lt;/span>&lt;span class="nt">a&lt;/span> &lt;span class="na">href&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="s">&amp;#34;/trend/79334789&amp;#34;&lt;/span>&lt;span class="p">&amp;gt;&lt;/span> #OnePlus7Series&lt;span class="p">&amp;lt;/&lt;/span>&lt;span class="nt">a&lt;/span>&lt;span class="p">&amp;gt;&amp;lt;/&lt;/span>&lt;span class="nt">li&lt;/span>&lt;span class="p">&amp;gt;&lt;/span>
&lt;span class="p">&amp;lt;&lt;/span>&lt;span class="nt">li&lt;/span> &lt;span class="na">class&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="s">&amp;#34;list-group-item&amp;#34;&lt;/span>&lt;span class="p">&amp;gt;&amp;lt;&lt;/span>&lt;span class="nt">a&lt;/span> &lt;span class="na">href&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="s">&amp;#34;/trend/79334788&amp;#34;&lt;/span>&lt;span class="p">&amp;gt;&lt;/span> #CelebrateWomen&lt;span class="p">&amp;lt;/&lt;/span>&lt;span class="nt">a&lt;/span>&lt;span class="p">&amp;gt;&amp;lt;/&lt;/span>&lt;span class="nt">li&lt;/span>&lt;span class="p">&amp;gt;&lt;/span>
&lt;span class="p">&amp;lt;&lt;/span>&lt;span class="nt">li&lt;/span> &lt;span class="na">class&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="s">&amp;#34;list-group-item&amp;#34;&lt;/span>&lt;span class="p">&amp;gt;&amp;lt;&lt;/span>&lt;span class="nt">a&lt;/span> &lt;span class="na">href&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="s">&amp;#34;/trend/79334787&amp;#34;&lt;/span>&lt;span class="p">&amp;gt;&lt;/span> #FelizMartes&lt;span class="p">&amp;lt;/&lt;/span>&lt;span class="nt">a&lt;/span>&lt;span class="p">&amp;gt;&amp;lt;/&lt;/span>&lt;span class="nt">li&lt;/span>&lt;span class="p">&amp;gt;&lt;/span>
&lt;span class="p">&amp;lt;&lt;/span>&lt;span class="nt">li&lt;/span> &lt;span class="na">class&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="s">&amp;#34;list-group-item&amp;#34;&lt;/span>&lt;span class="p">&amp;gt;&amp;lt;&lt;/span>&lt;span class="nt">a&lt;/span> &lt;span class="na">href&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="s">&amp;#34;/trend/79334786&amp;#34;&lt;/span>&lt;span class="p">&amp;gt;&lt;/span> #PESummit&lt;span class="p">&amp;lt;/&lt;/span>&lt;span class="nt">a&lt;/span>&lt;span class="p">&amp;gt;&amp;lt;/&lt;/span>&lt;span class="nt">li&lt;/span>&lt;span class="p">&amp;gt;&lt;/span>
&lt;span class="p">&amp;lt;/&lt;/span>&lt;span class="nt">ul&lt;/span>&lt;span class="p">&amp;gt;&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;/p>
&lt;!-- raw HTML omitted -->
&lt;p>First we import the libraries we&amp;rsquo;ll need&lt;/p>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-python" data-lang="python">&lt;span class="kn">from&lt;/span> &lt;span class="nn">bs4&lt;/span> &lt;span class="kn">import&lt;/span> &lt;span class="n">BeautifulSoup&lt;/span>
&lt;span class="kn">import&lt;/span> &lt;span class="nn">urllib&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;p>Then we&amp;rsquo;ll use &lt;code>urllib&lt;/code> to get the webpage. Read more about &lt;a href="https://docs.python.org/3/library/urllib.html">urllib&lt;/a>&lt;/p>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-python" data-lang="python">&lt;span class="n">URL&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="s2">&amp;#34;https://trendogate.com/place/23424977&amp;#34;&lt;/span>
&lt;span class="c1"># Open the URL&lt;/span>
&lt;span class="n">page&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">urllib&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">request&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">Request&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">URL&lt;/span>&lt;span class="p">)&lt;/span>
&lt;span class="n">result&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">urllib&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">request&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">urlopen&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">page&lt;/span>&lt;span class="p">)&lt;/span>
&lt;span class="c1"># Store the HTML page in a variable&lt;/span>
&lt;span class="n">resulttext&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">result&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">read&lt;/span>&lt;span class="p">()&lt;/span>
&lt;/code>&lt;/pre>&lt;/div>
&lt;p>Now we&amp;rsquo;ll create a &lt;code>BeautifulSoup&lt;/code> object from the HTML page we just retrieved. Read more about &lt;a href="https://www.crummy.com/software/BeautifulSoup/bs4/doc/">BeautifulSoup&lt;/a>&lt;/p>
&lt;div class="highlight">&lt;pre class="chroma">&lt;code class="language-python" data-lang="python">&lt;span class="c1"># Creates a nested data structure&lt;/span>
&lt;span class="n">soup&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">BeautifulSoup&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">resulttext&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="s1">&amp;#39;html.parser&amp;#39;&lt;/span>&lt;span class="p">)&lt;/span>
&lt;span class="c1"># Since we are interested only in an element with class &amp;#34;list-group&amp;#34;&lt;/span>
&lt;span class="c1"># We will search for all elements with that class in the soup&lt;/span>
&lt;span class="n">soup&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">soup&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">find_all&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">class_&lt;/span>&lt;span class="o">=&lt;/span> &lt;span class="s2">&amp;#34;list-group&amp;#34;&lt;/span>&lt;span class="p">)&lt;/span>
&lt;span class="c1"># Soup now contains an array of all elements with the class &amp;#34;list-group&amp;#34;&lt;/span>
&lt;span class="c1"># Since the Trending today list is the first on the page, it&amp;#39;s index is 0&lt;/span>
&lt;span class="n">trending_list&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">soup&lt;/span>&lt;span class="p">[&lt;/span>&lt;span class="mi">0&lt;/span>&lt;span class="p">]&lt;/span>
&lt;span class="c1"># Now we will iterate through the elements of the &amp;lt;ul&amp;gt; &lt;/span>
&lt;span class="c1"># &amp;lt;ul&amp;gt; has &amp;lt;li&amp;gt; tags nested inside&lt;/span>
&lt;span class="n">trending_tags&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="p">[]&lt;/span>
&lt;span class="k">for&lt;/span> &lt;span class="n">li&lt;/span> &lt;span class="ow">in&lt;/span> &lt;span class="n">trending_list&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">contents&lt;/span>&lt;span class="p">:&lt;/span>
&lt;span class="c1"># There is an &amp;lt;a&amp;gt; tag nested in each &amp;lt;li&amp;gt;&lt;/span>
&lt;span class="n">a&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">li&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">contents&lt;/span>&lt;span class="p">[&lt;/span>&lt;span class="mi">0&lt;/span>&lt;span class="p">]&lt;/span>
&lt;span class="c1"># The contents of &amp;#39;a&amp;#39; is just the text inside the tag&lt;/span>
&lt;span class="n">tag&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">a&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">contents&lt;/span>&lt;span class="p">[&lt;/span>&lt;span class="mi">0&lt;/span>&lt;span class="p">]&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">strip&lt;/span>&lt;span class="p">()&lt;/span>
&lt;span class="n">trending_tags&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">append&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">tag&lt;/span>&lt;span class="p">)&lt;/span>
&lt;span class="k">print&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">trending_tags&lt;/span>&lt;span class="p">)&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;p>Now we have scraped all of today&amp;rsquo;s trending hashtags from the website.&lt;/p>
&lt;h1 id="conclusion">Conclusion&lt;/h1>
&lt;p>This is just one of the ways that you can scrape information from websites. Another method is to use something like &lt;a href="https://www.selenium.dev/">Selenium&lt;/a> that allows you to emulate a browser instance and automate tasks with code.&lt;/p>
&lt;p>Here&amp;rsquo;s an article you can refer to, if you want to get started with Selenium: &lt;a href="https://www.toptal.com/python/web-scraping-with-python">https://www.toptal.com/python/web-scraping-with-python&lt;/a>&lt;/p>
&lt;!-- raw HTML omitted -->
&lt;!-- raw HTML omitted --></description></item></channel></rss>